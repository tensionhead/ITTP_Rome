{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scientific Computing with Python\n",
    "***\n",
    "\n",
    "<img align=\"left\" width=\"450\" height=\"500\" src=\"images/scientific_python.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Overview of the most used scientific Python libraries*\n",
    "\n",
    "\n",
    "In this chapter we will learn about the core scientific python stack (*SciPy stack*), meaning three major libraries: NumPy, Scipy and Matplotlib. Combined they represent a solid basis to do a lot of things like statistical data analysis, simulations and visualization. Before we start we should learn how we can import additional functionality into Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Setup - Importing Modules\n",
    "\n",
    "(reference: [http://swcarpentry.github.io/python-novice-gapminder/](http://swcarpentry.github.io/python-novice-gapminder/))\n",
    "\n",
    "Most of the power of a programming language is in its libraries.\n",
    "\n",
    "*   A *library* is a collection of files (called *modules*) that contains\n",
    "    functions for use by other programs. It may also contain data values (e.g., numerical constants) and other things.\n",
    "*   The [Python standard library](https://docs.python.org/3/library/) is an extensive suite of modules that comes\n",
    "    with Python itself.\n",
    "*   Many additional scientific libraries are already installed via **Anaconda** \n",
    "\n",
    "*Note: If you don't use the Anaconda suite, you can use [pip](https://pypi.org/project/pip/) to install additional libraries*.\n",
    "\n",
    "#### Libraries and modules\n",
    "\n",
    "> A library is a collection of modules, but the terms are often used\n",
    "> interchangeably, especially since many libraries only consist of a single\n",
    "> module, so don't worry if you mix them.\n",
    "\n",
    "\n",
    "#### A program must import a library module before using it.\n",
    "\n",
    "Use \n",
    "```Python\n",
    "import module\n",
    "```\n",
    "to load a library module into a program's *namespace*. Then you can refer to things from the module as\n",
    "\n",
    "```Python\n",
    "module.something\n",
    "```\n",
    "Python uses the `.` not only for methods attached to objects, but more generally to mean \"part of\".\n",
    "Here is how it works for the `time` module of the python standard library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# show formatted local time\n",
    "time.asctime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we called the function `asctime` from the module `time`. It can be a bit cumbersome to always refer to the module name, to import `asctime` directly into our *namespace* we can use the \n",
    "```Python \n",
    "from module import something```\n",
    "syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import asctime\n",
    "\n",
    "asctime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, suppose we are really lazy and we need to use (hence type) asctime a lot. In those cases we can define our own name for the part of the module we need: \n",
    "```Python\n",
    "from module import something as sth\n",
    "```\n",
    "For our example above we could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import asctime as atime\n",
    "\n",
    "atime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variants: \n",
    "```Python\n",
    "import module\n",
    "import module as m\n",
    "from module import something\n",
    "from module import something as sth\n",
    "```\n",
    "are equally valid, and it's more up to you and the code at hand what is best. Before we start doing something more useful, just a little reminder that you can use `DOUBLE-TAB` and the `?` symbol (as a shortcut for `help()`) also for modules and their contents. Another cool way of *introspection* is to use the built-in `dir()` function to list the contents of a module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, by using the `help(module.something)` you can now freely explore the modules contents. However some modules contain so much functionality that this list can get quickly overwhelming. In that case looking up the documentation online often makes more sense.  \n",
    "\n",
    "*Note: `dir()` is actually very powerful to explore namespaces in general, [here](https://www.geeksforgeeks.org/namespaces-and-scope-in-python/) is some further explanation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Easter Egg\n",
    "\n",
    "Ever heard of the *Zen of Python*? Try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A First Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "# The above line is a 'magic' line for the Jupyter notebook\n",
    "# Don't use it outside Jupyter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If installed on your system, loading additional modules into our Python program is very easy. We just need to know the name of the respective module. Let's load the standard plotting library of the scipy stack, matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# some 'data'\n",
    "x = range(5)\n",
    "y = [7, 3, 5, 8, 6]\n",
    "\n",
    "plt.plot(x, y, 'o--', color = 'teal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is a very extensive plotting library, for now we will just use the basic `plot` command to illustrate what we have to talk about next: Numpy *arrays*. Looking at arrays only via `print` statements is pretty tiring.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Crunching Numbers - Numpy\n",
    "\n",
    "NumPy (short for 'Numerical Python') is the foundation of almost all higher level scientific computing in Python. The reason for that is that it's basic `array` type is extremely versatile and extremely fast. So for all the expensive matrix operations many algorithms rely on, Numpy offers *pythonic* interfaces to the low-level numerical libraries BLAS and LAPACK (written in C and Fortran). \n",
    "\n",
    "There are a lot of different ways to construct NumPy array's, let's start with evenly spaced sequences using `arange`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing numpy in our namespace \n",
    "import numpy as np\n",
    "\n",
    "np.arange(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does that output remind you of something? Right, the Python built-in function `range()` also produces sequences of integers. NumPy's `arange` however also supports non-integer sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-2, 3, 0.5) #[start, stop, step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It's Fast\n",
    "\n",
    "The real difference to the built-in `range` concerns the speed with which we can do computations on that sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_number = int(1e7) # that is 10^7\n",
    "\n",
    "# built-in version\n",
    "large_list = list(range(large_number))\n",
    "result_bi = sum( large_list )\n",
    "\n",
    "# numpy version\n",
    "large_array = np.arange(large_number)\n",
    "result_np = np.sum( large_array )\n",
    "\n",
    "# math is math\n",
    "result_bi == result_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just have checked that summing up both sequences produces the same result. To test the performance we can use the `%timeit` magic from Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built_in version\n",
    "%timeit sum( large_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array from list\n",
    "large_array = np.array(large_list)\n",
    "\n",
    "# numpy version\n",
    "%timeit np.sum( large_array )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a speedup of around 15x! Note that the absolute numbers will be dependent on your CPU power. Finding such performance bottlenecks in your program can be hard. Using NumPy data types wherever possible is an easy way to try to stay performant.\n",
    "\n",
    "*Note: To test against the performance of the native data type `list`, the `range` object got casted to a `list` before the computation.*\n",
    "\n",
    "Arrays can not only be created by NumPy functions: calling `np.array()` on sequence-like data structures will work in most cases.\n",
    "\n",
    "Have you noticed that we used `sum()` and `np.sum()`? That is a good example of possible *namespace collision*: importing NumPy's `sum` directly (`from numpy import sum`), calling the built-in version is no longer possible! \n",
    "\n",
    "That's why it's good practice to import modules like this: `import numpy as np`. Those statements make the functions, variables and classes of a module available to your program, but keep them at arms length, in their own namespaces. This is to make sure that none of the names they use clash with anything in your program. It does mean that you have to type the prefix `np.` or `plt.` when you need to call them, but thatâ€™s not much of a price to pay for the safety that namespaces give you. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Everything is Vectorized\n",
    "\n",
    "One cool thing about NumPy is, that it correctly guesses what you want in most cases (*broadcasting*). Imagine you would like to sample the sine function over a certain time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "time_vec = np.linspace(0,15,50)\n",
    "y = np.sin(time_vec)\n",
    "\n",
    "plt.plot(time_vec, y, '.-', color = 'crimson')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you see it? We just put an **array in** the `np.sin` function and we got an **array out** holding all the function values! We've also got to know another function to construct arrays holding sequences: `np.linspace`. Can you find out how it works?\n",
    "\n",
    "Of course we can also call this sine function for just arbitrary two values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating the plot above\n",
    "plt.plot(time_vec, y, '.-', color = 'crimson')\n",
    "\n",
    "# just two time points\n",
    "t_points = [4, 9.5]\n",
    "y_points = np.sin(t_points)\n",
    "\n",
    "plt.plot(t_points, y_points, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all works, because in NumPy a lot of operations happen **element wise**. Here are few illustrating examples:\n",
    "\n",
    "##### Element wise Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x * x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x - 0.25 * x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Element wise Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square root\n",
    "np.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute value\n",
    "np.abs(x - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithm\n",
    "np.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Element wise Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equality\n",
    "x == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inequality\n",
    "x != 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The element wise comparisons are particularly interesting: they return *boolean arrays* holding only the values `True` and `False` indicating if a certain element fullfilled a condition or not. We soon will talk about indexing, where we will make good use of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1\n",
    "\n",
    "Take your time and experiment a bit inside the code cells! Then, try to compute the first ten powers of two ($2^0, 2^1, 2^2,...$) all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are of course many cases, where element wise application is not meaningful, e.g. computing a mean. In these cases NumPy applies the operation automatically to all elements together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynom or 3rd order \n",
    "x = np.linspace(-1,1, 5000)\n",
    "y = x**3\n",
    "\n",
    "# the mean\n",
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrema\n",
    "np.max(y), np.min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it's a good idea to plot the polynom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing with Sines\n",
    "In science, we very often have to deal with parameters. Say we want to express a sine with a certain amplitude $A$ and frequency $\\omega$:\n",
    "$$y(t) = A\\;sin(\\omega t)$$ NumPy lets us do this in a straightforward manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high amplitude and slow\n",
    "A = 3\n",
    "omega = 0.5\n",
    "y = A * np.sin(omega * time_vec)\n",
    "plt.plot(time_vec, y, '.-', color = 'teal')\n",
    "\n",
    "# low amplitude and faster\n",
    "A = 1.5\n",
    "omega = 1.67\n",
    "y = A * np.sin(omega * time_vec)\n",
    "plt.plot(time_vec, y,'.-', color = 'orange')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2\n",
    "\n",
    "After intense data analysis, we arrived at a model equation of the form:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\large\n",
    "y(t) = a \\; e^{-\\lambda t}\n",
    "\\end{equation*}\n",
    "\n",
    "Write a Python function accepting as argument a numpy array as the time vector and returning all the respective function values. Plot this function in the time interval $0 < t < 10$ for a few different parameters $a$ and $\\lambda$. (Hint: use `np.exp` for the exponential function)\n",
    "\n",
    "#### Exercise 3.3\n",
    "\n",
    "Re-use your function from exercise 3.2 above, to parameterize a sine with an exponentially decaying amplitude. Plot a few examples with different parameters, and try to use comments to let us (and your future self) know what's happening. (Hint: the amplitude of the sine is $A(t) \\sim e^{-\\lambda t}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excursus: Named and Default Arguments for Functions\n",
    "\n",
    "The functions of the last exercise give us a good moment to talk about handling function arguments. Sometimes, the number of arguments to a function can get quite large. Suppose for some reason we want to study families of third order polynoms: $ax + bx^2 + cx^3 + d$. Written as a Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly3(x, a, b, c, d):\n",
    "    return a * x + b * x**2 + c * x**3 + d\n",
    "\n",
    "# plot for one parameter set\n",
    "x = np.linspace(-1, 1, 500)\n",
    "y = poly3(x, 1, 1, -1, 0)\n",
    "\n",
    "plt.plot(x,y, lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the third argument for again? To not loose track what we are doing, or waste precious brain power on remembering argument orders, we can use *named arguments* in the call to `poly3`. In fact, by naming them explicitly, we don't have to remember their order as defined in the function definition. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for the same parameter set\n",
    "y = poly3(x, a = 1, c = -1, d = 0, b = 1 )\n",
    "\n",
    "plt.plot(x,y, lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now at least it's easy to see which argument value get's passed for what parameter. But we still have to supply five arguments each time we want to call our lovely `poly3`. Here the *default arguments* come to the rescue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly3(x, a = 1, b = 1, c = -1, d = 0):\n",
    "    return a * x + b * x**2 + c * x**3 + d\n",
    "\n",
    "# plot for the default parameters\n",
    "y = poly3(x) # only one argument!\n",
    "\n",
    "plt.plot(x,y, lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By putting assignments (the `=`'s) inside the function definition, we have set default values for the parameters a,b,c and d. With this it's easy to just vary one of them, and leave the other parameters fixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vary only the linear coefficient\n",
    "for a_val in np.linspace(-1,1,5):\n",
    "    y = poly3(x, a  = a_val)\n",
    "    plt.plot(x,y, lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite handy isn't it? Ah, and we haven't looped over numpy arrays yet, but I hope you are by now not surprised that this just works. \n",
    "\n",
    "In fact, many functions we can import from the SciPy stack (and other modules) accept a lot of arguments, e.g. `plt.plot()`. To still make them convenient to use, most of these arguments have default values.\n",
    "\n",
    "#### Exercise 3.4 \n",
    "Try to vary only the quadratic coeffcient in an interval $-1 < b < 1$ in our `poly3` function. Set the offset to $d = 3$ and plot the little parameter scan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### It's all about Shape\n",
    "\n",
    "So far we more or less blindly created numpy arrays with `np.arange` and `np.linspace` and everything just worked. Let's try to break things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.arange(5)\n",
    "x2 = np.arange(3)\n",
    "\n",
    "x1 * x2 # throws ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What happened here? Well we tried to multiply an array with length of 5 (x1) with an array of length 3 (x2). Neither the element wise nor the apply to all evaluation rule can make sense of that statement! Here is another example with arrays of dimension two: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones( (3,3) )\n",
    "b = 2 * np.ones( (3,2))\n",
    "\n",
    "print(a)\n",
    "print()\n",
    "print(b)\n",
    "\n",
    "a * b # another ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array dimensions are called *shape* in NumPy, and we can get to it by using the `.` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: In technical terms shape is an attribute of a numpy array. Note we also accesed it via the `.` syntax, however without `()` as for methods. Attributes are values attached to an object, whereas methods are functions attached to an object.*\n",
    "\n",
    "Array dimensions are always given by **row-wise ordering**, so b from above has 3 rows and 2 columns. Many functions of the SciPy stack take a shape parameter to create arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array filled with ones\n",
    "a = np.ones( (4,2) )\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array  filled with zeros\n",
    "b = np.zeros( (2,3) )\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random integers in [0,...,9]\n",
    "from numpy.random import randint\n",
    "c = randint(10, size = (3,3))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid running constantly into `ValueError`'s because of shape mismatches, it's good practice to initialize new arrays with the `.shape` of an existing one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones( (4,3) )\n",
    "b = randint(10, size = a.shape)\n",
    "\n",
    "# will never fail\n",
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the parameter for the `randint` function called *size* and not *shape*? Good question, maybe someone should bother the developers :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing and Axis\n",
    "\n",
    "How can we access individual elements of NumPy arrays? Here are some good news: very much as we learned it already for strings and lists! Check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(5)\n",
    "print( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd element\n",
    "print( x[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last two elements\n",
    "print( x[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every 2nd element\n",
    "print( x[::2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# litte list recap\n",
    "months = ['June', 'July', 'August']\n",
    "months[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait, what about multi-dimensional arrays? Ok true, here comes something new:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 x 3 matrix from [0,...,8]\n",
    "z = np.arange(9).reshape( (3,3) )\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st column\n",
    "print( z[:,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd row\n",
    "print( z[1,:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-indexing works by separating the different coordinates, called *axis* in NumPy, with a comma inside the square brackets `[axis0, axis1, ...]`. The 0th axis are the rows, 1st axis are the columns and so on for even higher dimensional arrays. The colon `:` signals that we want all elements of the respective axis.\n",
    "\n",
    "#### Exercise 3.5\n",
    "\n",
    "Using `np.reshape`, create a rectangular array from the 1-dimensional array `a = np.arange(12)`. Print all the columns of this 2d-array. (Hint: given the shape, try looping over the column indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boolean indexing\n",
    "\n",
    "We've already seen that comparison operators like `<, ==, !-` and so on work element wise and return a boolean array of the same shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(20).reshape( (4,5))\n",
    "print(a.shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who is divisible by 3?\n",
    "b = a%3 == 0\n",
    "print(b.shape)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly speaking, we don't know yet which of these numbers are divisble by three, but their coordinates are marked by `True` in the boolean array above. Now comes the amazing thing: we can directly use this boolean array to select the values which fullfil the condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a%3 == 0\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even shorter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[ a%3 == 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean indexing is extremely versatile, but can also be a bit tricky. Try not to do too much things at once, that helps with writing (and later still understanding) the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.6\n",
    "\n",
    "Try to find all values which are larger than 4, smaller or equal to 20 and divisible by 2 in the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(24).reshape( (3,8) )\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: We could achieve the same thing by explicitly looping over every single element in the array, and checking the condition. Not only being much more verbose, this is also very computationally ineffecient compared to working directly with the (boolean) arrays.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Functions Axis specific\n",
    "\n",
    "Quite often in real-world applications different *axis* have different meanings, say rows represent measurements taken for one sample and columns represent different samples. Have a look at some mock-up data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want Gaussian random variables\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# start with zero-filled-array\n",
    "mock_data = np.zeros( (500, 3) )\n",
    "\n",
    "# explicit is better than implicit\n",
    "NrPoints = mock_data.shape[0]\n",
    "\n",
    "# now put in the 'measurements'\n",
    "# for each sample: column by column\n",
    "mock_data[:,0] = randn( NrPoints ) + 3\n",
    "mock_data[:,1] = 1.5 * randn( NrPoints ) + 3\n",
    "mock_data[:,2] = 0.6 * randn( NrPoints ) + 1\n",
    "\n",
    "# plot a histogram\n",
    "h = plt.hist(mock_data, bins = 20)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we made use of the simple transformation from the standard Normal distribution $\\mathcal{N}(0,1)$ to Normal distributions with mean $\\mu$ and standard deviation $\\sigma$:\n",
    "\\begin{equation*}\n",
    "\\mathcal{N}(\\mu, \\sigma^2) \\sim \\sigma \\; \\mathcal{N}(0,1) + \\mu\n",
    "\\end{equation*}\n",
    "\n",
    "Now if we want to get the means of our three samples, we can try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mmh.. that's not we wanted right? That looks like the mean over the whole data array, which has no real meaning here. To calculate the mean *along* the time-axis we have to specify that we want to average *along* the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mock_data, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the shape of the returned array holding the mean values, it's the number of samples we have! If we specify the first axis, we average along the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.mean(mock_data, axis = 1)\n",
    "print(m)\n",
    "print(m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which again is not what we wanted.. To finish, let's plot the means together with the standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_means = np.mean(mock_data, axis = 0)\n",
    "# standard deviation, \n",
    "# works exactly like np.mean\n",
    "time_stds = np.std(mock_data, axis = 0)\n",
    "\n",
    "# position of the bars\n",
    "positions = np.arange( len(time_means) )\n",
    "\n",
    "# bar plot\n",
    "plt.bar(positions, time_means, yerr = time_stds, capsize = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of scientific Python functions take an `axis` argument, especially for statistical analysis. Checking the `.shape` attribute of the resulting arrays now and then is a good way to make sure we are still on the right track.\n",
    "\n",
    "#### Exercise 3.7\n",
    "Change the axis to `axis = 1` for **both** `np.mean` and `np.std` in the code above for the bar plot, what is happening there again?\n",
    "\n",
    "The plot admittedly is not very pretty, that's why we finally leave the nitty gritty details of numpy arrays and fully turn to plotting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plotting with Matplotlib and Seaborn\n",
    "\n",
    "As you've already noticed, the standard looks of Matplotlib are not the greatest (although you should've seen it a few years back..). Don't worry, you are not the only one! The good news is, that it's possible to customize every(!) little aspect of a plot to your needs. The bad news is, that the learning curve for that can be quite steep *and* long. Here we will try to take an intermediate route: we will do some face-lifting and customization but will refer for many details to online ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "# The above line is a 'magic' line for the Jupyter notebook\n",
    "# Don't use it outside Jupyter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Figure Adjustments\n",
    "\n",
    "Let's repeat our bar plot from above, this time we want more control about the looks:\n",
    "\n",
    "(if the following cell(s) don't run, re-evaluate all the cells from the [last section](#Applying-Functions-Axis-specific))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot') # choose a matplotlib style\n",
    "\n",
    "# create a figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot on axes 'ax'\n",
    "ax.bar(positions, time_means, yerr = time_stds, capsize = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib distinguishes between *figures* and *axes*. In our everyday language we would more refer to the *axes* as figures, as this is the place where the actual plotting happens. But well, some years ago the decision was made for these naming conventions. A Matplotlib *figure* is more like a frame, holding the *axes*. Note that instead of `plt.bar()` we called `ax.bar()` which controls on what axes the bar plot is drawn. To make that more clear, we can easily spawn two *axes* into one *figure*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure of size 12,4\n",
    "# and two axes within it\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12,4))\n",
    "\n",
    "ax1.bar(positions, time_means, yerr = time_stds, capsize = 5)\n",
    "\n",
    "# histogram of the 1st sample\n",
    "h = ax2.hist(mock_data[:,0], color = 'teal', bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok let's do some figure formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some labels\n",
    "labels = ['signal 1', 'signal 2', 'signal 3']\n",
    "\n",
    "# create a figure of size 12,4\n",
    "# and two axes within it\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12,4))\n",
    "\n",
    "ax1.bar(positions, time_means, yerr = time_stds, capsize = 5)\n",
    "\n",
    "# set the xticks and xticklabels\n",
    "# for the bar plot\n",
    "ax1.set_xticks( positions ) \n",
    "ax1.set_xticklabels( labels, rotation = 45, fontsize = 20)\n",
    "\n",
    "# let's put a label on the y-axis\n",
    "ax1.set_ylabel('Signal', fontsize = 20)\n",
    "\n",
    "# a title could also be nice\n",
    "ax1.set_title('Mean and Std', fontsize = 18)\n",
    "\n",
    "# --- format 2nd plot ---\n",
    "\n",
    "# label the x-axis, ticks are ok?!\n",
    "ax2.set_xlabel('Signal', fontsize = 20)\n",
    "ax2.set_ylabel('Counts', fontsize = 20)\n",
    "\n",
    "# title for ax2\n",
    "ax2.set_title('Signal 1', fontsize = 18)\n",
    "\n",
    "# show the 1st sample again, \n",
    "# this time with a label for the legend\n",
    "ax2.hist(mock_data[:,0], color = 'teal', bins = 30, label = labels[0] )\n",
    "\n",
    "# get a legend\n",
    "ax2.legend(fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uff.. that was a lot! Note that all formatting was done by calling the respective *methods* from the axes (`ax1` and `ax2`). It's up to you if you first set things like ticks and axis-labels, and then do the plotting or the other way around. \n",
    "\n",
    "Frankly, the only way forward in the beginning is to copy-paste parts of such example plotting code into your code, and make adjustments. Luckily, there are tons of Matplotlib [demos](https://matplotlib.org/gallery.html) out there, here are a few links:\n",
    "\n",
    "* [bar charts](https://matplotlib.org/gallery/statistics/barchart_demo.html)\n",
    "* [histograms](https://matplotlib.org/examples/statistics/histogram_demo_features.html)\n",
    "* [boxplots](https://matplotlib.org/examples/statistics/bxp_demo.html)\n",
    "* [filled plots](https://matplotlib.org/examples/lines_bars_and_markers/fill_demo_features.html)\n",
    "* [scatter plots](https://matplotlib.org/examples/shapes_and_collections/scatter_demo.html)\n",
    "\n",
    "\n",
    "#### Exercise 3.8\n",
    "\n",
    "Copy-paste the example from above and try to adjust a few things:\n",
    "* plot also the two other samples into the histogram (`ax2`) \n",
    "  (Hint: argument `color` can also be a list)\n",
    "* adjust the title of `ax2` accordingly\n",
    "* change the color of the bars in `ax1` to the colors shown in `ax2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy paste the last code cell above here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Specifiers - Lines and Points\n",
    "\n",
    "Have you noticed these cryptic `o-.` and alike mini-strings as arguments of the `plot()` command? It's acutally quite simple, they concisely encode most *marker styles* and *line styles* you ever want to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"350\" height=\"500\" src=\"images/mpl_linestyles.jpg\">\n",
    "<img align=\"left\" width=\"550\" height=\"500\" src=\"images/mpl_markers.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,20)\n",
    "\n",
    "# you can freely combine marker and linestyles:\n",
    "plt.plot(x, x**2, 'o--')\n",
    "plt.plot(x, x**3, 'p-')\n",
    "\n",
    "# defining them separately\n",
    "plt.plot(x, x**4, linestyle = '-.', marker = 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *linewidth* and *markersize* can be controlled by `lw` and `ms` parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, x**2, '^-',lw = .5, ms = 10)\n",
    "plt.plot(x, x**4, '*-',lw = 3, ms = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better Defaults - Seaborn\n",
    "\n",
    "[Seaborn](https://seaborn.pydata.org/) is a visualization library building on top of Matplotlib. It's goals are: \n",
    "* prettier defaults to need less customization to get to something nice looking\n",
    "* high-level interface to make customization easier\n",
    "\n",
    "Let's first activate seaborn and check a few of their color palettes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# seaborn defaults\n",
    "sns.palplot(sns.color_palette('pastel'))\n",
    "sns.palplot(sns.color_palette('bright'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color brewer palettes\n",
    "sns.palplot(sns.color_palette('BrBG',5))\n",
    "sns.palplot(sns.color_palette('RdGy',8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential palettes\n",
    "sns.palplot(sns.color_palette('Blues',3))\n",
    "sns.palplot(sns.color_palette('Reds',10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The importantness of choosing the right colors for you data visualizations can not be overstated. [Here](https://seaborn.pydata.org/tutorial/color_palettes.html) is the official seaborn documentation. Just one example how we can use them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(font_scale = 1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# get just 3 colors\n",
    "sns.set_palette('pastel')\n",
    "\n",
    "time_vec = np.linspace(0, 10, 100)\n",
    "omegas = [1,2,3]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,4))\n",
    "\n",
    "for omega in omegas:\n",
    "    y = np.sin(time_vec * omega)\n",
    "    plt.plot(time_vec, y)\n",
    "    \n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into more details, just note that with `sns.set(font_scale = 1.5)` we could conveniently set the fontsize for all labels and ticks on the plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Case Study - Fitting Functions\n",
    "\n",
    "So far we haven't used any of the higher algorithms provided by SciPy. Before picking one out of the blue, why not setting up a problem we want to solve? For this, we have some fluorescence lifetime measurements prepared in a file called `noisy_decay.txt`. Here is how we load it into a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt('noisy_decay.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.9a\n",
    "\n",
    "Check the dimensios of the data we got. Our trusty experimental collaborator has told us that the first column corresponds to time measured in nano seconds, the second column lists the recorded fluorescence intensities. Plot the recordings over time, and label the coordinate axes correspondingly. (Hint: Plot only markers, no lines. Try to experiment with the `alpha` parameter of the `.plot` command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that the decay of a fluorescence signal can be generally described by the following equation:\n",
    "\\begin{equation*}\n",
    "\\large\n",
    "I(t) = A \\; e^{-t/\\tau_0} + c\n",
    "\\end{equation*}\n",
    "\n",
    "#### Exercise 3.9b\n",
    "\n",
    "Encode this mathematical function into a Python function, and set some default parameters for $A$ and $c$. Then plot the model output with some guessed parameters together with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess guessing isn't it (pun intended)?! Our goal of course is to fit that model to our recorded data. How shall we start? Well what about [we google for it](http://lmgtfy.com/?q=Python+curve+fitting)?! With a bit of luck, we end up on this [SciPy documentation page](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html). That looks tough on first sight, right? Ok, first things first:\n",
    "\n",
    "#### Exercise 3.9c\n",
    "\n",
    "Import the scipy function `curve_fit` into our program. Then, from the webpage, try to find out how many and what arguments we have to supply to it, to make it work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.9d\n",
    "\n",
    "Do the curve fit for our model given the data, and try to make sense of the fitting output. (Hint: The output is described under `Returns:` in the documentation.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.9e\n",
    "\n",
    "Finally, let's plot our fitting result together with the data. What is the life-time of our unknown fluorophore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Summary\n",
    "\n",
    "* additional libraries can be loaded by `import` statements\n",
    "* NumPy `array`'s are the foundation of most scientific python programs\n",
    "* arrays have a `shape` and allow for `element wise` operations\n",
    "* Indexing arrays works very similar to Python lists, 3rd column: `a[:,2]` \n",
    "* `bool`ean arrays allow for efficient checking and selection of array elements\n",
    "* Default and named arguments make function calls much easier\n",
    "* Matplotlib can be used for a variety of plots (bar, lines,...)\n",
    "* `plt.plot()` gives fast results, `fig, ax = plt.subplots(...)` allows fine tuning\n",
    "* SciPy provides a lot of numerical routines for optimization, interpolation, statistics..\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
